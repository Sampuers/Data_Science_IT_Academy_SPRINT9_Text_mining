{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272a995b",
   "metadata": {},
   "source": [
    "### - Exercici 1\n",
    "##### Agafa un text en anglès que vulguis, i calcula'n la freqüència de les paraules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee740237",
   "metadata": {},
   "source": [
    "El texto que selecciono es un fragmento de una canción llamada 'Lover' de Taylor Swift. La frase dice 'Don't read the last page, but I stay when it's hard or it's wrong or we're making mistakes'. Refleja un compromiso emocional y estar presente en una relación a pesar de los desafios y los errores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd408f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sampu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sampu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cfc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frase de la canción\n",
    "frase = \"Don't read the last page, but I stay when it's hard or it's wrong or we're making mistakes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c345b32",
   "metadata": {},
   "source": [
    "Ahora voy a preprocesar la frase, primero haré tokenización para dividir el texto en palabras. Después quitaré las mayúsculas y los caracteres especiales y puntuaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3eaabae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do',\n",
       " \"n't\",\n",
       " 'read',\n",
       " 'the',\n",
       " 'last',\n",
       " 'page',\n",
       " ',',\n",
       " 'but',\n",
       " 'I',\n",
       " 'stay',\n",
       " 'when',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'hard',\n",
       " 'or',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'wrong',\n",
       " 'or',\n",
       " 'we',\n",
       " \"'re\",\n",
       " 'making',\n",
       " 'mistakes',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenización de palabras\n",
    "tokens = nltk.word_tokenize(frase)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b68171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converierto a minúsculas\n",
    "tokens = [word.lower() for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264f46aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do',\n",
       " 'read',\n",
       " 'the',\n",
       " 'last',\n",
       " 'page',\n",
       " 'but',\n",
       " 'i',\n",
       " 'stay',\n",
       " 'when',\n",
       " 'it',\n",
       " 'hard',\n",
       " 'or',\n",
       " 'it',\n",
       " 'wrong',\n",
       " 'or',\n",
       " 'we',\n",
       " 'making',\n",
       " 'mistakes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar puntuación y caracteres especiales\n",
    "tokens = [word for word in tokens if word.isalnum()]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0f3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2543e190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'it': 2, 'or': 2, 'do': 1, 'read': 1, 'the': 1, 'last': 1, 'page': 1, 'but': 1, 'i': 1, 'stay': 1, 'when': 1, 'hard': 1, 'wrong': 1, 'we': 1, 'making': 1, 'mistakes': 1})\n"
     ]
    }
   ],
   "source": [
    "# Calcular la frecuencia de las palabras sin utilizar stopwords i stemming\n",
    "\n",
    "word_freq = Counter(tokens)\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dcbbe2",
   "metadata": {},
   "source": [
    "### - Exercici 2\n",
    "##### Treu les stopwords i realitza stemming al teu conjunt de dades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cc411",
   "metadata": {},
   "source": [
    "Para hacer el preprocesamiento completo voy a aplicar el ejercicio2, Stopwords, que son eliminar palabras como 'a', 'the', etc., que no aportan significado especial para el análisi, así se reduce el ruido de los datos. Y en el caso del Stemming, se reducen las palabras a su raíz o forma base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f17469b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokens = [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99b99643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming \n",
    "stemmer = PorterStemmer()\n",
    "tokens = [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88c07fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['read', 'last', 'page', 'stay', 'hard', 'wrong', 'make', 'mistak']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d8c08",
   "metadata": {},
   "source": [
    "Ahora después del preprocesamiento voy a calcular la frecuencia de las palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1ec763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'read': 1, 'last': 1, 'page': 1, 'stay': 1, 'hard': 1, 'wrong': 1, 'make': 1, 'mistak': 1})\n"
     ]
    }
   ],
   "source": [
    "# Calcular la frecuencia de las palabras\n",
    "\n",
    "word_freq = Counter(tokens)\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdbd61",
   "metadata": {},
   "source": [
    "### - Exercici 3\n",
    "#### Realitza sentiment analysis al teu conjunt de dades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdf9d7",
   "metadata": {},
   "source": [
    "Vamos a realizar el análisis de sentimiento para determinar la actitud emocional del texto. Ayuda a comprender y clasificar el tono emocional detrás del conjunto de palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "349c9e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sampu\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "245d6246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "last\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "page\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "stay\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "hard\n",
      "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.1027}\n",
      "\n",
      "\n",
      "wrong\n",
      "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.4767}\n",
      "\n",
      "\n",
      "make\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "mistak\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicializa el analizador de sentimientos de NLTK\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#calculamos el sentimiento de cada palabra\n",
    "for word in tokens:\n",
    "    print(word)\n",
    "    print(analyzer.polarity_scores(word))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abb6669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.391, 'neu': 0.609, 'pos': 0.0, 'compound': -0.8402}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculamos el sentimiento del texto\n",
    "analyzer.polarity_scores(frase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c84c6a",
   "metadata": {},
   "source": [
    "Finalmente nos da 4 sentimientos con un porcentaje, en función de la frase analizada. \n",
    "\n",
    "En este caso, lo que nos dice es:\n",
    "- Existe un 39.1% se clasifica como negativo en términos de sentimiento.\n",
    "- Un 60.9% que se clasifica como neutro. \n",
    "- Un 0% se clarifica como positivo. \n",
    "\n",
    "El compound es una métrica compuesta que resume la polaridad del texto en su conjunto. Este valor varía entre -1 (indicando muy negativo) y 1 (indicando muy positivo)\n",
    "\n",
    "- Se entiende que el valor generadoees de -0.8402, por ello tiene una polariada negativa, ya que está más cercano a -1. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f6cef",
   "metadata": {},
   "source": [
    "CONCLUSIÓN: El análisis de sentimiento muestra que una parte pequeña del texto se clasifica como negativa, la mayoria como neutral y ninguna parte como positiva. En general el texto tiene una polaridad negativa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc48ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
